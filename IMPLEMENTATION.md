# Implementation Guide - MusicGen Local

Technical architecture and setup for developers working on the MusicGen Local MVP.

## ğŸ—ï¸ Architecture Overview

**Tech Stack:**
- **Frontend**: React 19 + Vite + TypeScript (port 3000)
- **Backend**: Python FastAPI 0.100+ (port 8000)
- **Queue**: Redis for job persistence (port 6379)
- **AI Engine**: DiffRhythm model (3.2GB, HuggingFace)
- **Storage**: SQLite for metadata, local filesystem for audio files

**Note:** Node.js is ONLY used for frontend development (npm, Vite). The entire backend runs on Python FastAPI.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React SPA     â”‚    â”‚  Python FastAPI â”‚    â”‚   Redis     â”‚
â”‚   (port 3000)   â”‚â—„â”€â”€â–ºâ”‚   (port 8000)   â”‚â—„â”€â”€â–ºâ”‚  (6379)     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚             â”‚
â”‚ â€¢ UI Screens    â”‚    â”‚ â€¢ REST API      â”‚    â”‚ â€¢ Job Queue â”‚
â”‚ â€¢ API Client    â”‚    â”‚ â€¢ DiffRhythm AI â”‚    â”‚ â€¢ Progress  â”‚
â”‚ â€¢ Routing       â”‚    â”‚ â€¢ Audio Loops   â”‚    â”‚             â”‚
â”‚                 â”‚    â”‚ â€¢ SQLite DB     â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Setup

### Prerequisites
- **Python 3.9+** (backend runtime)
- **Node.js 16+** (frontend dev only - npm/Vite)
- **Redis 7+** (job queue)
- **FFmpeg** (audio processing)
- **GPU recommended** (NVIDIA CUDA or Apple Silicon MPS)
- **10GB+ disk space** (for AI models)

### Local Development

```bash
# 1. Environment setup
cp .env.example .env

# 2. Backend setup (Python)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3. Frontend setup (npm for development only)
npm install

# 4. Start services (3 terminals)
# Terminal 1 - Redis
redis-server

# Terminal 2 - Python backend
python -m uvicorn python.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 3 - Frontend dev server
npm run dev
```

### Docker Development
```bash
docker-compose up --build
```

## ğŸ Python Backend (FastAPI)

### Project Structure

```
python/
â”œâ”€â”€ main.py                 # FastAPI app entry point
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ generate.py         # POST /api/generate - Music generation
â”‚   â”œâ”€â”€ loop.py             # POST /api/loop/jobs - Audio looping
â”‚   â””â”€â”€ metadata.py         # GET/PUT /api/tracks - Metadata CRUD
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas.py          # Pydantic models
â”‚   â””â”€â”€ database.py         # SQLite connection
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ diffrhythm.py       # DiffRhythm AI engine
â”‚   â”œâ”€â”€ audio_loop.py       # Audio loop creator
â”‚   â””â”€â”€ storage.py          # File management
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio.py            # Audio processing utilities
â”‚   â””â”€â”€ redis_client.py     # Redis job queue
â””â”€â”€ tests/
    â”œâ”€â”€ test_api.py
    â””â”€â”€ test_audio.py
```

### Key API Endpoints

**Generate Music**
```http
POST /api/generate
Content-Type: application/json

{
  "model": "DiffRhythm",
  "prompt": "Lo-fi hip hop with rain sounds",
  "duration": 180,
  "parameters": {
    "genre": "Electronic",
    "mood": "Relaxed"
  }
}

Response: 200 OK
{
  "job_id": "abc123",
  "status": "pending"
}
```

**Create Audio Loop**
```http
POST /api/loop/jobs
Content-Type: application/json

{
  "trackId": "track-123",
  "duration": 3600,
  "fadeInOut": true,
  "format": "mp3"
}

Response: 202 Accepted
{
  "id": "loop-456",
  "status": "PENDING",
  "progress": 0
}
```

**Get Loop Status**
```http
GET /api/loop/jobs/{jobId}

Response: 200 OK
{
  "id": "loop-456",
  "status": "COMPLETED",
  "progress": 100,
  "resultUrl": "/output/loop_track-123.mp3",
  "duration": 3600
}
```

### DiffRhythm AI Engine

```python
# python/services/diffrhythm.py
from diffusers import DiffusionPipeline
import torch

class DiffRhythmGenerator:
    def __init__(self):
        self.model_name = "ASLP-lab/DiffRhythm-full"
        self.cache_dir = "./models/cache"
        self.device = self._detect_device()
        self.pipeline = None
    
    def _detect_device(self):
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        return "cpu"
    
    def load_model(self):
        self.pipeline = DiffusionPipeline.from_pretrained(
            self.model_name,
            cache_dir=self.cache_dir,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        )
        self.pipeline.to(self.device)
    
    def generate(self, prompt: str, duration: int = 180):
        # Generate audio and return file path
        audio = self.pipeline(prompt, num_inference_steps=50).audio
        output_path = f"./output/{uuid.uuid4()}.mp3"
        # Save audio to file
        return output_path
```

## âš›ï¸ React Frontend (Vite)

### Project Structure

```
src/
â”œâ”€â”€ App.tsx                 # Main app with routing
â”œâ”€â”€ screens/
â”‚   â”œâ”€â”€ ModelSelectionScreen.tsx
â”‚   â”œâ”€â”€ DiffRhythmGeneratorScreen.tsx
â”‚   â”œâ”€â”€ ExportScreen.tsx
â”‚   â””â”€â”€ MetadataEditorScreen.tsx
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”œâ”€â”€ ProgressBar.tsx
â”‚   â””â”€â”€ MetadataEditorModal.tsx
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api.ts              # Axios HTTP client
â”‚   â””â”€â”€ loopService.ts      # Loop job polling
â””â”€â”€ types.ts                # TypeScript definitions
```

### Frontend Build & Serve

**Development:**
```bash
npm run dev  # Vite dev server on port 3000
```

**Production:**
```bash
npm run build  # Outputs to dist/
# Serve dist/ with Python:
python -m http.server 3000 --directory dist
```

## ğŸ§ª Testing

```bash
# Backend tests (Python)
pytest python/tests/ --cov=python

# Frontend tests (Node.js test runner)
npm test
```

## ğŸ“¦ Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for production setup.

**Environment Variables:**
```bash
# Python Backend
MODEL_CACHE_DIR=/app/models/cache
CUDA_VISIBLE_DEVICES=0  # GPU mode
REDIS_URL=redis://localhost:6379
MAX_CONCURRENT_JOBS=3
JOB_TIMEOUT=600

# Frontend Build (for production static serving)
VITE_API_URL=http://localhost:8000
```

## ğŸ”’ Security

- API keys in environment variables only
- File upload size limits (max 100MB)
- Input validation with Pydantic
- Rate limiting on generation endpoints
- CORS configured for frontend access
